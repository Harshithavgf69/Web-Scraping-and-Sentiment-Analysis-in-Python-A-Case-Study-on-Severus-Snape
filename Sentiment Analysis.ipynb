{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f9890-7581-4c5c-a9c3-3356d1658ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall nltk -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe97bc6e-ff68-4ab9-91da-07f96cf27ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b250c3b-3b5a-44eb-8d6a-690c94d52c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter Wiki\n",
      "READ MORE\n",
      "At least some content in this article is derived from information featured in: Harry Potter: Hogwarts Mystery & Harry Potter: Puzzles & Spells & Harry Potter: Magic Awakened & Harry Potter television series.As such, spoilers will be present within the article.\n",
      "Severus Snape\n",
      "\n",
      "\n",
      "Biographical information\n",
      "\n",
      "Born\n",
      "9 January 1960[1]Spinner's End, Cokeworth, Midlands, England, Great Britain\n",
      "\n",
      "\n",
      "Died\n",
      "2 May 1998 (aged 38)Shrieking Shack, Hogsmeade, Highlands, Scotland, Great Britain[2]\n",
      "\n",
      "\n",
      "Blood status\n",
      "Half-blood[3]\n",
      "\n",
      "\n",
      "Marital status\n",
      "Single\n",
      "\n",
      "\n",
      "Nationality\n",
      "English\n",
      "\n",
      "\n",
      "Also known as\n",
      "Half-Blood Prince[4]Snivellus/Snivelly[5][6][7] (by the Marauders and Lily Potter)Sev[7] (by Lily)Slytherus[8] (Potterwatch)The Potions Master[9]\n",
      "\n",
      "\n",
      "Title(s)\n",
      "Professor[10]Head of Slytherin House (formerly)Headmaster (formerly)\n",
      "\n",
      "\n",
      "\n",
      "Physical information\n",
      "\n",
      "Species\n",
      "Human[10]\n",
      "\n",
      "\n",
      "Gender\n",
      "Male[10]\n",
      "\n",
      "\n",
      "Hair colour\n",
      "Black[11][12]\n",
      "\n",
      "\n",
      "Eye colour\n",
      "Black[13][14]\n",
      "\n",
      "\n",
      "Skin colour\n",
      "Sallow[11][12]\n",
      "\n",
      "\n",
      "\n",
      "Relationship information\n",
      "\n",
      "Family members\n",
      "Tobias Snape (father)Eileen Snape (née Prince) (mother)Snape familyPrince family (maternal family)\n",
      "\n",
      "\n",
      "Romances\n",
      "Lily Potter (I) (unrequited) †[7]\n",
      "\n",
      "\n",
      "\n",
      "Magical characteristics\n",
      "\n",
      "Boggart\n",
      "Lord Voldemort[15]\n",
      "\n",
      "\n",
      "Wand\n",
      "Unknown length, wood and core\n",
      "\n",
      "\n",
      "Patronus\n",
      "Doe[7]\n",
      "\n",
      "\n",
      "\n",
      "Affiliation\n",
      "\n",
      "Occupation\n",
      "Potions Master at Hogwarts (1981-1996)Head of Slytherin House (1981-1997)Professor of Defence Against the Dark Arts at Hogwarts (1996-1997)[16]Headmaster of Hogwarts (1997-1998)\n",
      "\n",
      "\n",
      "House\n",
      "Slytherin[17]\n",
      "\n",
      "\n",
      "Loyalty\n",
      "Snape familyPrince familyHogwarts School of Witchcraft and WizardrySlytherinGang of Slytherins (formerly)Lord Voldemort (formerly)Death Eaters (defected)Albus DumbledoreOrder of the PhoenixLily PotterHarry Potter\n",
      "\n",
      "\n",
      "[Source]\n",
      "Professor Severus Snape (9 January 1960[1] – 2 May 1998)[2] was an English half-blood[3] wizard serving as Potions Master (1981-1996), Head of Slytherin House (1981-1997), Defence Against the Dark Arts professor (1996-1997), and Headmaster (1997-1998) of Hogwarts School of Witchcraft and Wizardry as well as a member of both the Order of the Phoenix and a Death Eater.\n",
      "His double life played an extremely important role in both of the Wizarding Wars against Voldemort.\n",
      "The only child of Muggle Tobias Snape and pure-blood witch Eileen Snape (née Prince), Severus was raised in the Muggle dwelling of Spinner's End, which was in close proximity to the home of the Evans family, though in a poorer area.\n",
      "He met Lily and Petunia Evans when he was nine.\n",
      "He fell deeply in love with Lily upon their meeting and became a close friend of hers.[7]\n",
      "Severus started at Hogwarts with Lily in the 1971–1972 school year, where he was Sorted into Slytherin House.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "url = 'https://harrypotter.fandom.com/wiki/Severus_Snape'\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    paragraphs = soup.find_all('p')\n",
    "\n",
    "    sentences = []\n",
    "    for paragraph in paragraphs:\n",
    "        text = paragraph.text.strip()\n",
    "        if text:\n",
    "            # Use regex to split on punctuation followed by space and capital letter\n",
    "            split_sentences = re.split(r'(?<=[.!?])\\s+(?=[A-Z])', text)\n",
    "            sentences.extend(split_sentences)\n",
    "\n",
    "    for sentence in sentences[:10]:\n",
    "        print(sentence)\n",
    "else:\n",
    "    print(f\"Request failed: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "231a1775-5417-4a39-887d-6fa67b24cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcde8def-1589-4cef-b77d-13d2d03495eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sentences = [re.sub(r'\\[.*?\\]', '', sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bfff37e-3df0-4418-8c9a-f46e9afe0de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sravya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sravya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.1-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.0 MB 2.0 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 2.1 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 2.1 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.4/11.0 MB 2.3 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.6/11.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.7/11.0 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.9/11.0 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.2/11.0 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.5/11.0 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.8/11.0 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.0/11.0 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 1.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 1.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.8/11.0 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.8/11.0 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.1/11.0 MB 1.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 7.3/11.0 MB 1.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 7.3/11.0 MB 1.5 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.6/11.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.4/11.0 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.7/11.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.7/11.0 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.9/11.0 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.9/11.0 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.2/11.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.0/11.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/11.0 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading numpy-2.3.1-cp313-cp313-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.7 MB 1.6 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.8/12.7 MB 1.6 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.0/12.7 MB 1.3 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 1.0/12.7 MB 1.3 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.3/12.7 MB 1.1 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 1.6/12.7 MB 1.1 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.8/12.7 MB 1.2 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 2.1/12.7 MB 1.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 2.6/12.7 MB 1.2 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.9/12.7 MB 1.3 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 3.1/12.7 MB 1.3 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 3.1/12.7 MB 1.3 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 3.1/12.7 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 3.4/12.7 MB 1.1 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.7/12.7 MB 1.1 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.7/12.7 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 3.9/12.7 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 4.2/12.7 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.5/12.7 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.7/12.7 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 5.0/12.7 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 5.0/12.7 MB 1.1 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 5.2/12.7 MB 1.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 5.2/12.7 MB 1.0 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 5.5/12.7 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 5.8/12.7 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.8/12.7 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 6.3/12.7 MB 1.0 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 6.6/12.7 MB 1.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.8/12.7 MB 1.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.3/12.7 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 7.9/12.7 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 8.1/12.7 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 8.7/12.7 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 8.9/12.7 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 9.4/12.7 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 9.7/12.7 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 10.2/12.7 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 10.5/12.7 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.7/12.7 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 11.0/12.7 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 11.5/12.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.1/12.7 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 1.3 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ---------------------------------------- 4/4 [pandas]\n",
      "\n",
      "Successfully installed numpy-2.3.1 pandas-2.3.1 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f108f03f-e374-4325-9e86-ee901bda132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\sravya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc14b73e-8c50-4cdb-a7de-84192bdd9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccacad4e-ef0e-44ca-9dc6-6de4549f30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DataFrame\n",
    "data = {'Sentences': cleaned_sentences}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "df.to_csv('sentences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29295a34-75f0-4239-ad0d-47402cf0861d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentences    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "965e4d65-deeb-4f7b-aaa7-ebd186eb9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove null values\n",
    "cleaned_df = df.dropna(subset=df.columns, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6970185e-540f-4ca2-8e25-6cea17c8616a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentences    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1e92817-d7f5-4c2a-afda-6c37f8828455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry Potter Wiki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>READ MORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At least some content in this article is deriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Severus Snape\\n\\n\\nBiographical information\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Professor Severus Snape (9 January 1960 – 2 Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>His double life played an extremely important ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The only child of Muggle Tobias Snape and pure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>He met Lily and Petunia Evans when he was nine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>He fell deeply in love with Lily upon their me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Severus started at Hogwarts with Lily in the 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences\n",
       "0                                  Harry Potter Wiki\n",
       "1                                          READ MORE\n",
       "2  At least some content in this article is deriv...\n",
       "3  Severus Snape\\n\\n\\nBiographical information\\n\\...\n",
       "4  Professor Severus Snape (9 January 1960 – 2 Ma...\n",
       "5  His double life played an extremely important ...\n",
       "6  The only child of Muggle Tobias Snape and pure...\n",
       "7    He met Lily and Petunia Evans when he was nine.\n",
       "8  He fell deeply in love with Lily upon their me...\n",
       "9  Severus started at Hogwarts with Lily in the 1..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d83b6242-c255-4d2c-9989-a4edeef36484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78ddfc97-2b03-4bca-ba9f-394a468cb24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "snape_life = cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "976c1975-9c51-4107-a71d-a70c3e43af8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry Potter Wiki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>READ MORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At least some content in this article is deriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Severus Snape\\n\\n\\nBiographical information\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Professor Severus Snape (9 January 1960 – 2 Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>His double life played an extremely important ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The only child of Muggle Tobias Snape and pure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>He met Lily and Petunia Evans when he was nine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>He fell deeply in love with Lily upon their me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Severus started at Hogwarts with Lily in the 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences\n",
       "0                                  Harry Potter Wiki\n",
       "1                                          READ MORE\n",
       "2  At least some content in this article is deriv...\n",
       "3  Severus Snape\\n\\n\\nBiographical information\\n\\...\n",
       "4  Professor Severus Snape (9 January 1960 – 2 Ma...\n",
       "5  His double life played an extremely important ...\n",
       "6  The only child of Muggle Tobias Snape and pure...\n",
       "7    He met Lily and Petunia Evans when he was nine.\n",
       "8  He fell deeply in love with Lily upon their me...\n",
       "9  Severus started at Hogwarts with Lily in the 1..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snape_life.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef65cda9-61c1-477f-bb7d-055c40fdaa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Professor Severus Snape (9 January 1960 – 2 Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>His double life played an extremely important ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The only child of Muggle Tobias Snape and pure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He met Lily and Petunia Evans when he was nine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He fell deeply in love with Lily upon their me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Severus started at Hogwarts with Lily in the 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This put him in the same year as Lily but unfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Severus became the immediate enemy of James Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This led him to be irritable towards James's s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Snape, when young, developed a passion for the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences\n",
       "0  Professor Severus Snape (9 January 1960 – 2 Ma...\n",
       "1  His double life played an extremely important ...\n",
       "2  The only child of Muggle Tobias Snape and pure...\n",
       "3    He met Lily and Petunia Evans when he was nine.\n",
       "4  He fell deeply in love with Lily upon their me...\n",
       "5  Severus started at Hogwarts with Lily in the 1...\n",
       "6  This put him in the same year as Lily but unfo...\n",
       "7  Severus became the immediate enemy of James Po...\n",
       "8  This led him to be irritable towards James's s...\n",
       "9  Snape, when young, developed a passion for the..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snape_life = snape_life[4:]\n",
    "snape_life = snape_life.reset_index(drop=True)\n",
    "snape_life.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "108ceaf1-7db7-4c4d-9f73-969a1d937456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Professor Severus Snape (9 January 1960 – 2 Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>His double life played an extremely important ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The only child of Muggle Tobias Snape and pure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He met Lily and Petunia Evans when he was nine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He fell deeply in love with Lily upon their me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Severus started at Hogwarts with Lily in the 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This put him in the same year as Lily but unfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Severus became the immediate enemy of James Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This led him to be irritable towards James's s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Snape, when young, developed a passion for the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences\n",
       "0  Professor Severus Snape (9 January 1960 – 2 Ma...\n",
       "1  His double life played an extremely important ...\n",
       "2  The only child of Muggle Tobias Snape and pure...\n",
       "3    He met Lily and Petunia Evans when he was nine.\n",
       "4  He fell deeply in love with Lily upon their me...\n",
       "5  Severus started at Hogwarts with Lily in the 1...\n",
       "6  This put him in the same year as Lily but unfo...\n",
       "7  Severus became the immediate enemy of James Po...\n",
       "8  This led him to be irritable towards James's s...\n",
       "9  Snape, when young, developed a passion for the..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snape_life.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d247fab-9e32-4f47-af7d-8f2bd9b753d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\sravya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Professor Severus Snape (9 January 1960 – 2 Ma...</td>\n",
       "      <td>-0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>His double life played an extremely important ...</td>\n",
       "      <td>-0.0276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The only child of Muggle Tobias Snape and pure...</td>\n",
       "      <td>-0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He met Lily and Petunia Evans when he was nine.</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He fell deeply in love with Lily upon their me...</td>\n",
       "      <td>0.8261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Severus started at Hogwarts with Lily in the 1...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This put him in the same year as Lily but unfo...</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Severus became the immediate enemy of James Po...</td>\n",
       "      <td>-0.8591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This led him to be irritable towards James's s...</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Snape, when young, developed a passion for the...</td>\n",
       "      <td>0.7184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  Sentiment\n",
       "0  Professor Severus Snape (9 January 1960 – 2 Ma...    -0.3400\n",
       "1  His double life played an extremely important ...    -0.0276\n",
       "2  The only child of Muggle Tobias Snape and pure...    -0.5994\n",
       "3    He met Lily and Petunia Evans when he was nine.     0.0000\n",
       "4  He fell deeply in love with Lily upon their me...     0.8261\n",
       "5  Severus started at Hogwarts with Lily in the 1...     0.0000\n",
       "6  This put him in the same year as Lily but unfo...    -0.4767\n",
       "7  Severus became the immediate enemy of James Po...    -0.8591\n",
       "8  This led him to be irritable towards James's s...    -0.4767\n",
       "9  Snape, when young, developed a passion for the...     0.7184"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import os\n",
    "\n",
    "# Step 1: Download vader_lexicon if not already done\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Step 2: Force nltk to look in your user folder where it downloaded\n",
    "nltk.data.path.append(os.path.expanduser('~') + '/AppData/Roaming/nltk_data')\n",
    "\n",
    "# Step 3: Create analyzer (this now works)\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Step 4: Apply sentiment analysis\n",
    "snape_life['Sentences'] = snape_life['Sentences'].fillna('')\n",
    "snape_life['Sentiment'] = snape_life['Sentences'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "# Step 5: Preview\n",
    "snape_life.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "520c184e-2706-4fc3-8dcd-571098561a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_angry = -0.7\n",
    "threshold_anguish = -0.5\n",
    "threshold_contempt = -0.05\n",
    "threshold_worry = 0\n",
    "threshold_ambiguity = 0.1\n",
    "threshold_affection = 0.2  \n",
    "threshold_sacrifice = 0.3\n",
    "threshold_protectiveness = 0.5\n",
    "threshold_sarcasm = 0.6\n",
    "\n",
    "# Create conditions and corresponding labels\n",
    "conditions = [\n",
    "    snape_life['Sentiment'] <= threshold_angry,\n",
    "    (snape_life['Sentiment'] > threshold_angry) & (snape_life['Sentiment'] <= threshold_anguish),\n",
    "    (snape_life['Sentiment'] > threshold_anguish) & (snape_life['Sentiment'] <= threshold_contempt),\n",
    "    (snape_life['Sentiment'] > threshold_contempt) & (snape_life['Sentiment'] <= threshold_worry),\n",
    "    (snape_life['Sentiment'] > threshold_worry) & (snape_life['Sentiment'] <= threshold_ambiguity),\n",
    "    (snape_life['Sentiment'] > threshold_ambiguity) & (snape_life['Sentiment'] <= threshold_affection),\n",
    "    (snape_life['Sentiment'] > threshold_affection) & (snape_life['Sentiment'] <= threshold_sacrifice),\n",
    "    (snape_life['Sentiment'] > threshold_sacrifice) & (snape_life['Sentiment'] <= threshold_protectiveness),\n",
    "    (snape_life['Sentiment'] > threshold_protectiveness) & (snape_life['Sentiment'] <= threshold_sarcasm),\n",
    "    snape_life['Sentiment'] > threshold_sarcasm\n",
    "]\n",
    "\n",
    "labels = ['angry', 'anguish', 'contempt', 'worry','ambiguity', 'affection', 'sacrifice', 'protectiveness', 'sarcasm', 'unknown']\n",
    "\n",
    "# Create a new column with the sentiment categories\n",
    "snape_life['Emotion_Category'] = np.select(conditions, labels, default='unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56b1ae7d-a16a-45ae-8c0c-2377778c08dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotion_Category\n",
       "worry             22.810591\n",
       "contempt          18.635438\n",
       "angry             15.478615\n",
       "anguish           12.219959\n",
       "protectiveness    10.386965\n",
       "unknown            9.266802\n",
       "sarcasm            3.665988\n",
       "sacrifice          3.360489\n",
       "affection          2.138493\n",
       "ambiguity          2.036660\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_percentages = snape_life['Emotion_Category'].value_counts(normalize=True) * 100\n",
    "emotion_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0369a238-75c9-4511-88f1-eb52ee61991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sravya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sravya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1f2bda7-b71d-496f-bca4-75e33eaf6cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\sravya/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sravya/nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sravya/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookup Error: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\sravya/nltk_data'\n",
      "    - 'C:\\\\Users\\\\sravya\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\sravya\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\share\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\sravya\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\sravya\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\sravya/Downloads/nltk_data'\n",
      "    - 'C:\\\\Users\\\\sravya/Downloads/nltk_data'\n",
      "    - 'C:\\\\Users\\\\sravya/AppData/Roaming/nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "Try restarting your kernel and ensure nltk data is properly downloaded.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Force re-download (ensures it's there)\n",
    "nltk.download('punkt', download_dir=nltk.data.path[0])\n",
    "nltk.download('stopwords', download_dir=nltk.data.path[0])\n",
    "nltk.download('wordnet', download_dir=nltk.data.path[0])\n",
    "\n",
    "# Re-import with safety\n",
    "try:\n",
    "    all_text = ' '.join(snape_life['Sentences'].astype(str))\n",
    "\n",
    "    # Tokenize\n",
    "    words = word_tokenize(all_text)\n",
    "\n",
    "    # Remove stopwords + punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "\n",
    "    # Frequency distribution\n",
    "    freq_dist = FreqDist(lemmatized_words)\n",
    "\n",
    "    # Top 5 words\n",
    "    top_words = freq_dist.most_common(5)\n",
    "\n",
    "    # Print result\n",
    "    for word, frequency in top_words:\n",
    "        print(f\"The word '{word}' appears {frequency} times.\")\n",
    "\n",
    "except LookupError as e:\n",
    "    print(\"Lookup Error:\", e)\n",
    "    print(\"Try restarting your kernel and ensure nltk data is properly downloaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b059ccc-51e4-4de1-8dba-be9d5dcb88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "\n",
    "# Set a clean nltk_data folder in Downloads\n",
    "nltk_data_path = os.path.expanduser('~/Downloads/nltk_data')\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "# Create folder if it doesn't exist\n",
    "os.makedirs(nltk_data_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b53b3fc-3e4a-4189-b882-22cb23337712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sravya/Downloads/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sravya/Downloads/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sravya/Downloads/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download each required corpus\n",
    "nltk.download('punkt', download_dir=nltk_data_path)\n",
    "nltk.download('stopwords', download_dir=nltk_data_path)\n",
    "nltk.download('wordnet', download_dir=nltk_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46f4c175-867b-40f4-868d-4471779bfa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sravya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sravya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sravya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')          # for word_tokenize and sent_tokenize\n",
    "nltk.download('stopwords')      # for stopword filtering\n",
    "nltk.download('wordnet')        # for lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffede731-4181-491f-9f0f-afb2da01c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(nltk_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65b4c06f-554a-46e0-a088-c7f2413fae1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'snape' appears 718 times.\n",
      "The word 'harry' appears 250 times.\n",
      "The word 'him' appears 248 times.\n",
      "The word 'voldemort' appears 190 times.\n",
      "The word 'dumbledore' appears 174 times.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Combine all sentences into one string\n",
    "all_text = ' '.join(snape_life['Sentences'].dropna().astype(str))\n",
    "\n",
    "# Lowercase the text\n",
    "all_text = all_text.lower()\n",
    "\n",
    "# Use regex to extract words (alphanumeric only)\n",
    "words = re.findall(r'\\b[a-zA-Z]{2,}\\b', all_text)\n",
    "\n",
    "# List of basic stopwords (since we're not using nltk stopwords)\n",
    "basic_stopwords = set([\n",
    "    'the', 'is', 'and', 'a', 'an', 'to', 'of', 'in', 'on', 'that', 'it', 'for',\n",
    "    'this', 'was', 'with', 'as', 'by', 'are', 'at', 'from', 'but', 'or', 'he',\n",
    "    'she', 'we', 'they', 'you', 'his', 'her', 'its', 'be', 'have', 'has', 'had'\n",
    "])\n",
    "\n",
    "# Filter out stopwords\n",
    "filtered_words = [word for word in words if word not in basic_stopwords]\n",
    "\n",
    "# Count frequencies\n",
    "word_freq = Counter(filtered_words)\n",
    "\n",
    "# Get top 5 most common\n",
    "top_words = word_freq.most_common(5)\n",
    "\n",
    "# Display\n",
    "for word, freq in top_words:\n",
    "    print(f\"The word '{word}' appears {freq} times.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "938fd91c-6332-46e9-bd31-bf8fd98b218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "snape_life.to_csv('snape_life_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c899e4-2170-4680-a63b-d8cfc328eeaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
